{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c0372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import ast\n",
    "import shutil\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b452c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root directory\n",
    "root_dir = \"../../models/experiments\"\n",
    "\n",
    "# Get all subdirectories\n",
    "experiment_dirs = glob.glob(f\"{root_dir}/*/*/\")\n",
    "\n",
    "# Initialize an empty list to hold all experiment data\n",
    "experiments_data = []\n",
    "\n",
    "# Loop over each subdirectory\n",
    "for exp_dir in experiment_dirs:\n",
    "    # Config file path\n",
    "    config_file = f\"{exp_dir}hyperparameters.json\"\n",
    "\n",
    "    # If config file doesn't exist, continue to next directory\n",
    "    if not glob.glob(config_file):\n",
    "        print(\"config file does not exist.\")\n",
    "        continue\n",
    "\n",
    "    # Load config data\n",
    "    with open(config_file, 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "        \n",
    "    # Result file patterns\n",
    "    result_file = f\"{exp_dir}results/use_case_results.json\"\n",
    "\n",
    "    if not glob.glob(result_file):\n",
    "        print(\"result file not found\")\n",
    "        continue\n",
    "\n",
    "    # Load result data\n",
    "    with open(result_file, 'r') as f:\n",
    "        use_case_result_data = json.load(f)\n",
    "\n",
    "    # Merge config data and result data\n",
    "    experiment_data = {**config_data, **use_case_result_data}\n",
    "\n",
    "    # Add folder information\n",
    "    experiment_data[\"results_folder\"] = '/'.join(exp_dir.split('/')[1:-1])\n",
    "\n",
    "    # Append to list\n",
    "    experiments_data.append(experiment_data)\n",
    "\n",
    "# Convert list of dictionaries to pandas DataFrame\n",
    "df = pd.DataFrame(experiments_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9973cf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2153ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('experimental_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba1503c",
   "metadata": {},
   "source": [
    "## Start here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a3d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('experimental_results.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e97c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~((df['method'] == 'loss') & (df['lambda_soc'] != 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b110e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom order of 'method' column\n",
    "custom_order = ['data_baseline', 'loss', 'pretrain', 'architecture', 'hybrid', 'residual']\n",
    "\n",
    "# Convert 'method' column to categorical with custom order\n",
    "df['method'] = pd.Categorical(df['method'], categories=custom_order, ordered=True)\n",
    "\n",
    "# Define the mapping for renaming categorical values\n",
    "mapping = {'data_baseline': 'Data Baseline', 'loss': 'Loss', 'pretrain': 'Initialization', 'architecture': 'Architecture', 'hybrid': 'Hybrid', 'residual': 'Residual'}\n",
    "\n",
    "# Use the replace() method to rename categorical values\n",
    "df['method'] = df['method'].replace(mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee793571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c595d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3013c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = df[df['method'] == 'loss']\n",
    "#loss_df['lambda_soc'] = loss_df['lambda_soc'].astype(str)\n",
    "grouped_loss = loss_df.groupby(['lambda_soc', 'n_features', 'n_lstm_layers', 'n_epochs'])[['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1cb5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lambda_soc'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce16a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter data for n_features = 4\n",
    "# filtered_df = df[(df['n_epochs'] == 20) & (df['method'] == 'loss')]\n",
    "\n",
    "# # Group by 'lambda_soc' and calculate the mean RMSE\n",
    "# grouped_lambda = filtered_df.groupby('lambda_soc').mean()\n",
    "\n",
    "# # Find the lambda with the lowest mean RMSE\n",
    "# best_lambda = grouped_lambda['avg_rmse'].idxmin()\n",
    "\n",
    "# print(f\"The best performing lambda  is: {best_lambda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813cd663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filter data for n_features = 4 (you can adjust this filter as needed)\n",
    "# filtered_df = df[(df['n_features'] == 1) & (df['method'] == 'residual')]\n",
    "\n",
    "# # Group by 'n_lstm_layers' and calculate the mean RMSE\n",
    "# grouped_lstm = filtered_df.groupby('n_lstm_layers').mean()\n",
    "\n",
    "# # Find the n_lstm_layers value with the lowest mean RMSE\n",
    "# best_lstm_layers = grouped_lstm['avg_rmse'].idxmin()\n",
    "\n",
    "# print(f\"The best performing n_lstm_layers value is: {best_lstm_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9114c78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_loss = grouped_loss.reset_index().pivot(index=['n_features', 'lambda_soc'], columns=['n_lstm_layers', 'n_epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10992184",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Define the values for n_features, n_lstm_layers, and n_epochs\n",
    "n_features_values = [1, 2, 3, 4]\n",
    "n_lstm_layers_values = [1, 2]\n",
    "n_epochs_values = [10, 20, 50]\n",
    "\n",
    "# Generate all combinations of the values\n",
    "combinations = list(product(n_features_values, n_lstm_layers_values, n_epochs_values))\n",
    "\n",
    "# Define the RMSE values for use cases and average\n",
    "method = 'Theory Baseline'\n",
    "use_case_1_rmse = 4.4\n",
    "use_case_2_rmse = 13.4\n",
    "use_case_3_rmse = 15.7\n",
    "avg_rmse = 11.2  # Average of the three use cases\n",
    "\n",
    "# Create a list to hold the data for the DataFrame\n",
    "data = []\n",
    "\n",
    "# Iterate over each combination and create a row with the same RMSE values\n",
    "for n_features, n_lstm_layers, n_epochs in combinations:\n",
    "    data.append([method, n_features, n_lstm_layers, n_epochs, use_case_1_rmse, use_case_2_rmse, use_case_3_rmse, avg_rmse])\n",
    "\n",
    "# Create the DataFrame\n",
    "columns = ['method', 'n_features', 'n_lstm_layers', 'n_epochs', 'use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse']\n",
    "theory_baseline_df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# Display the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa9c4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_list = []\n",
    "for idx, rmse in enumerate(['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse']):\n",
    "\n",
    "    # Calculate the mean of avg_rmse for each group\n",
    "    grouped_means = pd.concat([theory_baseline_df, df]).groupby(['method', 'n_features', 'n_lstm_layers', 'n_epochs'])[rmse].mean().reset_index()\n",
    "\n",
    "    # Function to determine best, second best, and worst performing methods for each group\n",
    "    def determine_performance(group):\n",
    "        group = group.sort_values(rmse)  # Sort the group by avg_rmse\n",
    "        best = group.iloc[0]['method']\n",
    "        worst = group.iloc[-1]['method']\n",
    "\n",
    "        second_best = group.iloc[1]['method'] if len(group) > 1 else None  # Check if there is a second best method\n",
    "        third_best = group.iloc[2]['method'] if len(group) > 2 else None\n",
    "        fourth_best = group.iloc[3]['method'] if len(group) > 3 else None\n",
    "        fifth_best = group.iloc[4]['method'] if len(group) > 4 else None\n",
    "        sixth_best = group.iloc[5]['method'] if len(group) > 5 else None\n",
    "\n",
    "        return pd.Series({'Best': best, '2nd best': second_best, 'Worst': worst,\n",
    "                          '3rd best': third_best, '4th best': fourth_best,\n",
    "                          '5th best': fifth_best, '6th best': sixth_best})\n",
    "\n",
    "    # Apply the function to each group and reset the index\n",
    "    performance_df = grouped_means.groupby(['n_features', 'n_lstm_layers', 'n_epochs']).apply(determine_performance).reset_index()\n",
    "\n",
    "    # Merge output columns into multi-columns of n_features, n_lstm_layers, and n_epochs\n",
    "    performance_df.columns = pd.MultiIndex.from_tuples([('n_features', ''), ('n_lstm_layers', ''), ('n_epochs', ''),\n",
    "                                                        ('Best', ''), ('2nd best', ''), ('3rd best', ''),\n",
    "                                                        ('4th best', ''), ('5th best', ''), ('6th best', ''),\n",
    "                                                        ('Worst', '')])\n",
    "\n",
    "    performance_list.append(performance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3967a6bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "method_counts_list = []\n",
    "\n",
    "for performance_df in performance_list:\n",
    "    # Flatten the 'Best' and 'Worst' columns\n",
    "    best_flat = performance_df['Best'].dropna()\n",
    "    worst_flat = performance_df['Worst'].dropna()\n",
    "\n",
    "    # Count the occurrences of each method in the flattened columns\n",
    "    best_counts = best_flat.value_counts().astype(int)\n",
    "    worst_counts = worst_flat.value_counts().astype(int)\n",
    "\n",
    "    # Create a DataFrame with the method names and their corresponding best and worst counts\n",
    "    method_counts_df = pd.DataFrame({'Best Count': best_counts, 'Worst Count': worst_counts})\n",
    "    method_counts_df.index.name = 'Method'\n",
    "\n",
    "    # Append the counts DataFrame to the list\n",
    "    method_counts_list.append(method_counts_df)\n",
    "\n",
    "# Print the list of DataFrames containing best and worst counts for each performance DataFrame\n",
    "for idx, method_counts_df in enumerate(method_counts_list, 1):\n",
    "    print(f\"Performance DataFrame {idx}:\")\n",
    "    print(method_counts_df)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033839bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "best_counts = []\n",
    "worst_counts = []\n",
    "\n",
    "for performance_df in performance_list:\n",
    "    # Flatten the 'Best' and 'Worst' columns\n",
    "    best_flat = performance_df['Best'].dropna()\n",
    "    worst_flat = performance_df['Worst'].dropna()\n",
    "\n",
    "    # Count the occurrences of each method in the flattened columns\n",
    "    best_counts.append(best_flat.value_counts())\n",
    "    worst_counts.append(worst_flat.value_counts())\n",
    "\n",
    "# Concatenate the counts for all DataFrames in 'performance_list'\n",
    "best_counts_df = pd.concat(best_counts, axis=1).fillna(0).sum(axis=1).astype(int)\n",
    "worst_counts_df = pd.concat(worst_counts, axis=1).fillna(0).sum(axis=1).astype(int)\n",
    "\n",
    "# Create a DataFrame with the method names and their corresponding best and worst counts\n",
    "method_counts_df = pd.DataFrame({'Best Count': best_counts_df, 'Worst Count': worst_counts_df})\n",
    "method_counts_df.index.name = 'Method'\n",
    "\n",
    "method_counts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5a3178",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_list[0] # 0 -3 for Reproduction, ... , AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a804ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = df.groupby(['method', 'n_features', 'n_lstm_layers', 'n_epochs'])[['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse']].mean()\n",
    "#grouped_df = df.groupby(['method', 'n_features', 'n_lstm_layers', 'n_epochs'])[['avg_rmse']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c947a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb56edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = grouped_df.reset_index().pivot(index=['method', 'n_features'], columns=['n_lstm_layers', 'n_epochs'])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf817b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results = grouped_df.reset_index().pivot(index=['method', 'n_features'], columns=['n_lstm_layers', 'n_epochs'])\n",
    "results = grouped_df.reset_index().pivot(index=['method'], columns=['n_lstm_layers', 'n_epochs', 'n_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9fc534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe1d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "SMALL_SIZE = 14\n",
    "MEDIUM_SIZE = 14\n",
    "BIGGER_SIZE = 20\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)\n",
    "plt.rc('legend', fontsize=12)\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)\n",
    "\n",
    "titles = ['Reproduction', 'Abstraction', 'Generalization']\n",
    "\n",
    "melted_df = df.melt(id_vars=['method', 'n_features'], value_vars=['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse'],\n",
    "                    var_name='number_of_features', value_name='rmse')\n",
    "\n",
    "theory_baseline = [4.4, 13.4, 15.7, 11.2]\n",
    "\n",
    "for i, feature in enumerate(melted_df['number_of_features'].unique(), 1):\n",
    "    fig, ax = plt.subplots(figsize=(10, 2.5), dpi=140)\n",
    "    \n",
    "    plt.axhline(y=theory_baseline[i-1], color='red', linestyle='--', linewidth=0.6)\n",
    "    \n",
    "    if i == 1:\n",
    "        plt.text(-0.8, theory_baseline[i-1] + 2, \"Theory\", fontsize=14)\n",
    "    else:\n",
    "        plt.text(-0.8, theory_baseline[i-1] - 7 , \"Theory\", fontsize=14)\n",
    "    \n",
    "    if i == 1:\n",
    "        plt.text(-0.34, 40, \"Number of Features:\", fontsize=12)\n",
    "        plt.text(-0.34, 32, \"1\", fontsize=12)\n",
    "        plt.text(-0.14, 32, \"2\", fontsize=12)\n",
    "        plt.text(0.06, 32, \"3\", fontsize=12)\n",
    "        plt.text(0.24, 32, \"4\", fontsize=12)\n",
    "        \n",
    "\n",
    "    ax = sns.boxplot(data=melted_df[melted_df['number_of_features'] == feature], x='method', y='rmse', hue='n_features', fill=None, legend=False, showbox=True, showfliers=False, linewidth=0.7)\n",
    "    #plt.setp(ax.artists, edgecolor = 'k', facecolor='w')\n",
    "    plt.setp(ax.lines, color='k')    \n",
    "    if i != 3:\n",
    "        plt.gca().set_xticklabels([])\n",
    "        \n",
    "\n",
    "    \n",
    "    plt.text(5.4, 45, titles[i-1], fontsize=14, horizontalalignment='right')\n",
    "    plt.xlabel(None)\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.ylim(0, 60)\n",
    "    plt.xlim(-0.9, 5.5)\n",
    "    plt.tick_params(bottom=True, top=False, left=True, right=False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    #fig.savefig(f'boxplot_results_{i}.pdf', format='pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf67e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['method'] == 'Residual'][['use_case_3_rmse', 'results_folder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81afd016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'method' and find the minimum RMSE per column\n",
    "lowest_rmse_per_method = df.groupby('method').min()\n",
    "\n",
    "# Reset the index to make 'method' a regular column\n",
    "lowest_rmse_per_method.reset_index(inplace=True)\n",
    "\n",
    "print(\"Lowest RMSE per use case and avg_rmse per method:\")\n",
    "lowest_rmse_per_method[['method', 'use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = []\n",
    "\n",
    "for rmse in ['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse']:\n",
    "    # Calculate the average avg_rmse per method, n_features, n_lstm_layers, and n_epochs\n",
    "    df_grouped = df.groupby(['method', 'n_features', 'n_lstm_layers', 'n_epochs']).agg({rmse: ['mean', 'std']}).reset_index()\n",
    "    \n",
    "    # Sort by mean value\n",
    "    df_sorted = df_grouped.sort_values((rmse, 'mean'))\n",
    "    \n",
    "    # Select the configuration with the lowest mean for each method\n",
    "    best.append(df_sorted.groupby('method').first().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e900ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d4ade2",
   "metadata": {},
   "source": [
    "## Add std to the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['method'] == 'Data Baseline') & (df['n_features'] == 1) & (df['n_lstm_layers'] == 1) & (df['n_epochs'] == 20) ][['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse', 'results_folder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb88e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['method'] == 'Hybrid') & (df['n_features'] == 1) & (df['n_lstm_layers'] == 1) & (df['n_epochs'] == 50) ][['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse', 'results_folder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['method'] == 'Residual') & (df['n_features'] == 3) & (df['n_lstm_layers'] == 2) & (df['n_epochs'] == 50) ][['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse', 'results_folder']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae17609",
   "metadata": {},
   "outputs": [],
   "source": [
    "best[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3764c462",
   "metadata": {},
   "outputs": [],
   "source": [
    "best[3].iloc[:, [0, 4, 5]].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = []\n",
    "\n",
    "for rmse in ['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse']:\n",
    "    filtered_df = df[df['n_features'] == 4]\n",
    "    # Calculate the average avg_rmse per method, n_features, n_lstm_layers, and n_epochs\n",
    "    best.append(filtered_df.groupby(['method', 'n_features', 'n_lstm_layers', 'n_epochs']).agg({rmse: ['mean', 'std']}).reset_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d826b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60750581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d101f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f31bc9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = []\n",
    "for rmse in ['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse']:\n",
    "    # Calculate the average avg_rmse per method, n_features, n_lstm_layers, and n_epochs\n",
    "    grouped_avg_rmse = df.groupby(['method', 'n_features', 'n_lstm_layers', 'n_epochs'])[rmse].mean().reset_index()\n",
    "\n",
    "    # Find the best performing (lowest avg_rmse) per method\n",
    "    best_performing = grouped_avg_rmse.groupby('method').apply(lambda x: x[x[rmse] == x[rmse].min()])\n",
    "    \n",
    "\n",
    "\n",
    "    best.append(best_performing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfee1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923bcc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "best[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "best[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc364650",
   "metadata": {},
   "outputs": [],
   "source": [
    "best[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6698c6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the results and create the final DataFrame\n",
    "best_df = pd.concat(best).reset_index(drop=True)\n",
    "\n",
    "# # Rename columns to match the desired table\n",
    "# best_df = best_df.rename(columns={'use_case_1_rmse': 'best use case 1 rmse',\n",
    "#                                    'use_case_2_rmse': 'best use case 2 rmse',\n",
    "#                                    'use_case_3_rmse': 'best use case 3 rmse',\n",
    "#                                    'avg_rmse': 'best avg_rmse'})\n",
    "\n",
    "# Select and reorder columns\n",
    "best_df = best_df[['method', 'use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse']]\n",
    "\n",
    "print(\"Best performing RMSE per method:\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174dcc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_combinations = best_df.groupby('method')[['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse']].mean()\n",
    "best_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57086a88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theory_baseline_row = pd.DataFrame([['Theory Baseline', 4.4, 13.4, 15.7, 11.2]], columns=['method', 'use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse'])\n",
    "print_result = pd.concat([theory_baseline_row, best_combinations.reset_index()], ignore_index=True).round(1)\n",
    "print_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5446b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(print_result.iloc[:, 1:5].style.format('{:.1f}'.format).to_latex(hrules=True, multirow_align='t'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ff38fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_4_features = []\n",
    "for rmse in ['use_case_1_rmse', 'use_case_2_rmse', 'use_case_3_rmse', 'avg_rmse']:\n",
    "    filtered_df = df[df['n_features'] == 4]\n",
    "    # Calculate the average avg_rmse per method, n_features, n_lstm_layers, and n_epochs\n",
    "    grouped_avg_rmse_4 = filtered_df.groupby(['method', 'n_features', 'n_lstm_layers', 'n_epochs'])[rmse].mean().reset_index()\n",
    "\n",
    "    # Find the best performing (lowest avg_rmse) per method\n",
    "    best_performing_4 = grouped_avg_rmse_4.groupby('method').apply(lambda x: x[x[rmse] == x[rmse].min()])\n",
    "    \n",
    "\n",
    "\n",
    "    best_4_features.append(best_performing_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49bf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_4_features[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af23eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_4_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33972668",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_4_features[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c60407",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_4_features[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

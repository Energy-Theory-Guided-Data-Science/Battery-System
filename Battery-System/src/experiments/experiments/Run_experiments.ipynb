{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbe13dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 16:49:56.817881: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 16:49:56.938040: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-08 16:49:57.338933: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/bielskip/miniconda3/envs/battery-system/lib/\n",
      "2024-05-08 16:49:57.338984: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:$LD_LIBRARY_PATH:/home/i40/bielskip/miniconda3/envs/battery-system/lib/\n",
      "2024-05-08 16:49:57.338989: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import context\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from numba import cuda \n",
    "import json\n",
    "import traceback\n",
    "import time\n",
    "import random\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from multiprocessing import Manager\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import src.data.data_preprocessing as util\n",
    "import src.models.lstm_model as lstm_vanilla # data baseline, pretrain, hybrid\n",
    "import src.models.lstm_loss_model as lstm_loss # loss\n",
    "import src.models.lstm_architecture_model as lstm_arch # architecture\n",
    "import src.models.lstm_residual_model as lstm_residual # residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee8735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(hyper_params):\n",
    "    np.random.seed(hyper_params['seed'])\n",
    " \n",
    "    \n",
    "    print(\"run_exp\")\n",
    "\n",
    "    while True:\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        experiment_path = f\"../../../models/experiments/{hyper_params['experiment_name']}/{timestamp}\"\n",
    "\n",
    "        model_save_path = f'{experiment_path}/model'\n",
    "        results_path = f'{experiment_path}/results'\n",
    "\n",
    "        try:\n",
    "            os.makedirs(model_save_path)\n",
    "            os.makedirs(results_path)\n",
    "            break\n",
    "        except FileExistsError:\n",
    "            time.sleep(random.randint(2, 30))\n",
    "            continue\n",
    "\n",
    "    hyper_params['model_save_path'] = model_save_path\n",
    "    hyper_params['results_path'] = results_path\n",
    "    hyper_params['n_features'] = len(hyper_params['input_features'])\n",
    "    with open(f'{experiment_path}/hyperparameters.json', 'w') as json_file:\n",
    "        json.dump(hyper_params, json_file, indent=4)\n",
    "\n",
    "        \n",
    "    \n",
    "    # Prepare Training Data\n",
    "    TRAINING_SETS =  np.load('../../../models/training_setup/training_sets.npy', allow_pickle=True)\n",
    "    TRAINING_SETS = TRAINING_SETS.item()\n",
    "    training_sets = TRAINING_SETS['10A_all']  \n",
    "    X_list, y_list, scalers_train,  = util.prepare_all_features_input(hyper_params, training_sets, hyper_params['stack'], hyper_params['cell'])\n",
    "    \n",
    "    # Prepare Test Data\n",
    "    TEST_SETS =  np.load('../../../models/training_setup/test_sets.npy', allow_pickle=True)\n",
    "    TEST_SETS = TEST_SETS.item()\n",
    "    test_profiles_usecase_1 = TEST_SETS['Reproduction']\n",
    "    test_profiles_usecase_2 = TEST_SETS['Abstraction']\n",
    "    test_profiles_usecase_3 = TEST_SETS['Generalization']\n",
    "    X_case_1, y_case_1, _  = util.prepare_all_features_input(hyper_params, test_profiles_usecase_1, hyper_params['stack'], hyper_params['cell'])\n",
    "    X_case_2, y_case_2, _  = util.prepare_all_features_input(hyper_params, test_profiles_usecase_2, hyper_params['stack'], hyper_params['cell'])\n",
    "    X_case_3, y_case_3, _  = util.prepare_all_features_input(hyper_params, test_profiles_usecase_3, hyper_params['stack'], hyper_params['cell'])\n",
    "    \n",
    "    \n",
    "    # select the train input features\n",
    "    X_list_features = []\n",
    "    feature_idx = [hyper_params['feature_indices'][feature] for feature in hyper_params['input_features']]\n",
    "    for array in X_list:\n",
    "        X_list_features.append(array[:, :, feature_idx])    \n",
    "\n",
    "    # train TGDS methods\n",
    "    if hyper_params['method'] == 'data_baseline':\n",
    "        lstm = lstm_vanilla.Model()\n",
    "        lstm.initialize(hyper_params)\n",
    "        lstm.train_f(X_list_features, y_list, scalers_train)\n",
    "        lstm.test_usecases(X_case_1[0][:, :, feature_idx], y_case_1[0], X_case_2[0][:, :, feature_idx], y_case_2[0], X_case_3[0][:, :, feature_idx], y_case_3[0], scalers_train)\n",
    "    \n",
    "    elif hyper_params['method'] == 'pretrain':\n",
    "        lstm = lstm_vanilla.Model()\n",
    "        lstm.initialize(hyper_params)\n",
    "        # train first half on the theory-output\n",
    "        y_list_pretrain = []\n",
    "        for array in X_list:\n",
    "            y_list_pretrain.append(array[:, 99, 4]) # Theory model\n",
    "        lstm.train_f(X_list_features, y_list_pretrain, scalers_train, half_train=True) \n",
    "        # train the second half with standard output\n",
    "        lstm.train_f(X_list_features, y_list, scalers_train, half_train=True)\n",
    "        lstm.test_usecases(X_case_1[0][:, :, feature_idx], y_case_1[0], X_case_2[0][:, :, feature_idx], y_case_2[0], X_case_3[0][:, :, feature_idx], y_case_3[0], scalers_train)\n",
    "    \n",
    "    elif hyper_params['method'] == 'hybrid':\n",
    "        # add theory output to the input features\n",
    "        feature_idx.append(4)\n",
    "        X_list_features = []\n",
    "        for array in X_list:\n",
    "            X_list_features.append(array[:, :, feature_idx]) \n",
    "        hyper_params['n_features'] = len(hyper_params['input_features']) + 1\n",
    "        \n",
    "        lstm = lstm_vanilla.Model()\n",
    "        lstm.initialize(hyper_params)\n",
    "        lstm.train_f(X_list_features, y_list, scalers_train)\n",
    "        lstm.test_usecases(X_case_1[0][:, :, feature_idx], y_case_1[0], X_case_2[0][:, :, feature_idx], y_case_2[0], X_case_3[0][:, :, feature_idx], y_case_3[0], scalers_train)\n",
    "\n",
    "    elif hyper_params['method'] == 'loss':\n",
    "        lstm = lstm_loss.Model()\n",
    "        lstm.initialize(hyper_params, scalers_train)\n",
    "        lstm.train_f(X_list_features, y_list, scalers_train)\n",
    "        lstm.test_usecases(X_case_1[0][:, :, feature_idx], y_case_1[0], X_case_2[0][:, :, feature_idx], y_case_2[0], X_case_3[0][:, :, feature_idx], y_case_3[0], scalers_train)\n",
    "\n",
    "    elif hyper_params['method'] == 'architecture':\n",
    "        # prepare conditional input as initial voltage\n",
    "        cond_train = []\n",
    "        for array in X_list:\n",
    "            cond_train.append(array[:, 98:99, 2])\n",
    "        X_list_features_cond_train = [[X_list_features[idx], cond_train[idx]] for idx in range(len(cond_train))]        \n",
    "        \n",
    "        lstm = lstm_arch.Model()\n",
    "        lstm.initialize(hyper_params)\n",
    "        lstm.train_f(X_list_features_cond_train, y_list, scalers_train)\n",
    "        lstm.test_usecases([X_case_1[0][:, :, feature_idx], X_case_1[0][:, 98:99, 2]], y_case_1[0], [X_case_2[0][:, :, feature_idx], X_case_2[0][:, 98:99, 2]], y_case_2[0], [X_case_3[0][:, :, feature_idx], X_case_3[0][:, 98:99, 2]], y_case_3[0], scalers_train)\n",
    "    \n",
    "    elif hyper_params['method'] == 'residual':\n",
    "        # prepare residual output\n",
    "        residual_y_list = []\n",
    "        for array in X_list:\n",
    "            residual_y_list.append(array[:, 98:99, 5]) # residual   \n",
    "            \n",
    "        lstm = lstm_residual.Model()\n",
    "        lstm.initialize(hyper_params)\n",
    "        lstm.train_f(X_list_features, residual_y_list, scalers_train)\n",
    "        lstm.test_usecases(X_case_1[0][:, :, feature_idx], y_case_1[0], X_case_1[0][:, 98:99, 4], X_case_2[0][:, :, feature_idx], y_case_2[0], X_case_2[0][:, 98:99, 4], X_case_3[0][:, :, feature_idx], y_case_3[0], X_case_3[0][:, 98:99, 4], scalers_train)\n",
    "    else:\n",
    "        print(\"Unknown method.\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13693b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(config, gpu_queue):\n",
    "    gpu_id = int(gpu_queue.get())\n",
    "\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(tf.config.list_physical_devices(\"GPU\")[gpu_id], True)\n",
    "        tf.config.set_visible_devices(tf.config.list_physical_devices(\"GPU\")[gpu_id], \"GPU\")\n",
    "\n",
    "        run_experiment(config)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        traceback.print_exc()\n",
    "\n",
    "    gpu_queue.put(gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcdfc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.python.client import device_lib\n",
    "\n",
    "# def get_available_gpus():\n",
    "#     local_device_protos = device_lib.list_local_devices()\n",
    "#     return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "# get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee27018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_test_tgds(hyper_params):\n",
    "    hyper_params['experiment_name'] = 'test_tgds_methods'\n",
    "    configs = []\n",
    "    for method in [\"residual\"]:\n",
    "        for input_features in [['current'], ['current', 'charge'], ['current', 'charge', 'init_vol'], ['current', 'charge', 'init_vol', 'ocv']]:\n",
    "            config = hyper_params.copy()\n",
    "            config['input_features'] = input_features\n",
    "            config['method'] = method\n",
    "            configs.append(config)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec176bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_all_but_loss_params_config(hyper_params):\n",
    "    hyper_params['experiment_name'] = 'all_but_loss_params_config'\n",
    "    configs = []\n",
    "    for run in range(5):\n",
    "        for method in [\"data_baseline\", \"architecture\", \"pretrain\", \"hybrid\", \"residual\"]\n",
    "            for num_layers in [1, 2]:\n",
    "                for epochs in [10, 20, 50]:\n",
    "                    for input_features in [['current'], ['current', 'charge'], ['current', 'charge', 'init_vol'], ['current', 'charge', 'init_vol', 'ocv']]:\n",
    "\n",
    "                            config = hyper_params.copy()\n",
    "                            config['seed'] = run\n",
    "                            config['method'] = method\n",
    "                            config['n_lstm_layers'] = num_layers  \n",
    "                            config['n_epochs'] = epochs\n",
    "                            config['input_features'] = input_features\n",
    "                            configs.append(config)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba15718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_loss_parsams_config(hyper_params):\n",
    "    hyper_params['experiment_name'] = 'loss_params_config'\n",
    "    hyper_params['method'] = 'loss'\n",
    "    configs = []\n",
    "    for run in range(5):\n",
    "        for lambda_soc in [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "            for num_layers in [1, 2]:\n",
    "                for epochs in [10, 20, 50]:\n",
    "                    for input_features in [['current'], ['current', 'charge'], ['current', 'charge', 'init_vol'], ['current', 'charge', 'init_vol', 'ocv']]:\n",
    "                        config = hyper_params.copy()\n",
    "                        config['seed'] = run\n",
    "                        config['lambda_soc'] = lambda_soc\n",
    "                        config['n_lstm_layers'] = num_layers  \n",
    "                        config['n_epochs'] = epochs\n",
    "                        config['input_features'] = input_features\n",
    "                        configs.append(config)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f427361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ex_baseline_parsams_config(hyper_params):\n",
    "    configs = []\n",
    "    for run in range(3):\n",
    "        for num_layers in [1, 2]:\n",
    "            for epochs in [10, 20, 50]:\n",
    "                for input_features in [['current'], ['current', 'charge'], ['current', 'charge', 'init_vol'], ['current', 'charge', 'init_vol', 'ocv']]:\n",
    "\n",
    "                        config = hyper_params.copy()\n",
    "                        config['seed'] = run\n",
    "                        config['n_lstm_layers'] = num_layers  \n",
    "                        config['n_epochs'] = epochs\n",
    "                        config['input_features'] = input_features\n",
    "                        configs.append(config)\n",
    "    return configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ebeca08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_exprun_exp\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 16:49:58.717805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.717993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.718013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.718269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.741748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.741962: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.742032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.742098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.742356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.742359: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.742615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:49:58.742759: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:16.434608: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 16:50:16.436669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:16.436917: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:16.437079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:16.797077: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:16.797273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:16.797419: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:16.797552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:81:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Residual_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 20)           1760      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,061\n",
      "Trainable params: 5,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 16:50:17.666981: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2024-05-08 16:50:18.105313: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      " 25%|███████████▎                                 | 1/4 [00:35<01:46, 35.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 16:50:45.465088: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-08 16:50:45.466958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:45.467177: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:45.467319: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:45.814354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:45.814554: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:45.814699: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-05-08 16:50:45.814834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22287 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:c1:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Residual_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 100, 20)           1840      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,141\n",
      "Trainable params: 5,141\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 16:50:46.673106: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2024-05-08 16:50:47.105917: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Residual_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100, 20)           1920      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,221\n",
      "Trainable params: 5,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████████████▌                      | 2/4 [01:04<01:03, 31.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_exp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|█████████████████████████████████▊           | 3/4 [01:09<00:19, 19.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Residual_LSTM\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 100, 20)           2000      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 20)                3280      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,301\n",
      "Trainable params: 5,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [01:38<00:00, 24.62s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define available GPUs\n",
    "gpus = [\"0\", \"1\"]\n",
    "methods = [\"data_baseline\", \"loss\", \"architecture\", \"pretrain\", \"hybrid\", \"residual\"]\n",
    "\n",
    "\n",
    "# Example list of configurations\n",
    "hyper_params = np.load('../../../models/training_setup/hyperparameters.npy', allow_pickle=True).item()\n",
    "#hyper_params['method'] = 'data_baseline'\n",
    "hyper_params['n_epochs'] = 2\n",
    "hyper_params['n_steps'] = 100\n",
    "hyper_params['seed'] = 0\n",
    "#hyper_params['experiment_name'] = 'explore_baseline_params'\n",
    "#hyper_params['input_features'] = ['current', 'charge', 'init_vol', 'ocv']\n",
    "\n",
    "# # Create configurations\n",
    "# configs = []\n",
    "# for run in range(2):\n",
    "#     config = hyper_params.copy()\n",
    "#     config['seed'] = run  \n",
    "#     configs.append(config)\n",
    "\n",
    "#configs = ex_baseline_parsams_config(hyper_params)\n",
    "\n",
    "configs = ex_test_tgds(hyper_params)\n",
    "\n",
    "with Manager() as manager:\n",
    "    gpu_queue = manager.Queue()\n",
    "    for gpu_id in gpus:\n",
    "        gpu_queue.put(gpu_id)\n",
    "\n",
    "    with ProcessPoolExecutor(max_workers=len(gpus)) as executor:\n",
    "        futures = [executor.submit(worker, config, gpu_queue) for config in configs]\n",
    "\n",
    "        for _ in tqdm(concurrent.futures.as_completed(futures), total=len(configs)):\n",
    "            pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5286ac66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_experiment(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

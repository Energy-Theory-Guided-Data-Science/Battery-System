{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy import ndimage \n",
    "tf.compat.v1.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------- Utility Functions -------------------------------------------\n",
    "\"\"\" Creates subsequences of the original sequence to fit LSTM structure\n",
    " \n",
    "Args:\n",
    "    sequence_1: the first sequence which gets converted into multiple subarrays of length: n_steps\n",
    "    sequence_2: the second sequence, each n_steps'th element will be part of the output array\n",
    "    n_steps: the amount of time steps used as an input into the LSTM for prediction\n",
    "\n",
    "Returns:\n",
    "    A tuple of 2 numpy arrays in the required format\n",
    "    \n",
    "    X.shape = (X.shape[0] - n_steps, n_steps)\n",
    "    y.shape = (X.shape[0] - n_steps, 1)\n",
    "\n",
    "\"\"\"\n",
    "def subsequences(sequence_X, sequence_y, n_steps):\n",
    "    if n_steps > len(sequence_X):\n",
    "        raise Exception('subsequences: n_steps should not exceed the sequence length')\n",
    "    \n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequence_X)):\n",
    "        end_ix = i + n_steps\n",
    "\n",
    "        if end_ix > len(sequence_X):\n",
    "            break\n",
    "\n",
    "        X.append(sequence_X[i:end_ix])\n",
    "        y.append(sequence_y[end_ix-1])\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "\"\"\" Subsample array to decrease the amount of data\n",
    "\n",
    "Args:\n",
    "    sequence: the input array to be subsampled\n",
    "    d_sample: sample frequency, meaning every d_sample'th element will be part of the output\n",
    "    \n",
    "Returns:\n",
    "    The subsampled array\n",
    "\n",
    "\"\"\"\n",
    "def subsample(sequence, d_sample):\n",
    "    return sequence[::d_sample]\n",
    "\n",
    "\n",
    "\"\"\" Smooth array to decrease measurement noise\n",
    "\n",
    "Args: \n",
    "    sequence: the input array to be smoothed\n",
    "    sigma: parameter for the gauss filtering\n",
    "\n",
    "Returns:\n",
    "    The smoothed array\n",
    "\"\"\"\n",
    "def smooth(sequence, sigma):\n",
    "    return ndimage.filters.gaussian_filter(sequence, sigma)\n",
    "\n",
    "\n",
    "\"\"\" Aligns two sequences\n",
    "\n",
    "    In this context this means subsampling the first array so that it afterwards has the same size as the second array\n",
    "    \n",
    "Args: \n",
    "    sequence_1: arrray to be aligned\n",
    "    sequence_2: array to be aligned to\n",
    "    \n",
    "Returns:\n",
    "    The algined array\n",
    "\"\"\"\n",
    "def align(sequence_1, sequence_2):\n",
    "    if len(sequence_1) < len(sequence_2):\n",
    "        raise Exception('align: missmatch of sequence lengths')\n",
    "    \n",
    "    sample_ratio = sequence_1.shape[0] / sequence_2.shape[0]\n",
    "\n",
    "    aligned_sequence = list()\n",
    "    for i in range(len(sequence_2)):\n",
    "        aligned_sequence.append(sequence_1[int(np.round(i * sample_ratio))])\n",
    "\n",
    "    aligned_sequence = np.array(aligned_sequence)\n",
    "    \n",
    "    return aligned_sequence\n",
    "\n",
    "\n",
    "\"\"\" Prepares the data for input into the LSTM\n",
    "\n",
    "    Preparation incudes:\n",
    "    subsampling, smoothing, aligning differnt sized sequences and reshaping the sequence to the requested format\n",
    "    \n",
    "Args:\n",
    "    input_sequence: the input feature sequence\n",
    "    label_sequence: the output/groud truth sequence\n",
    "    aligned: indicates if input and label sequence are of equal size or need alignment\n",
    "    d_sample: sample frequency\n",
    "    n_steps: the amount of time steps used as an input into the LSTM for prediction\n",
    "    sigma: parameter for the data smoothing\n",
    "\n",
    "Returns:\n",
    "    A tuple of 3 values. The prepared input sequence X, the output sequence of labels y and the scaler component for y. \n",
    "    This is needed afterwards to scale the output back to the original value range\n",
    "\"\"\"\n",
    "def prepare_data(input_sequence, label_sequence, aligned, d_sample, n_steps, sigma):\n",
    "    # align data if not of equal size\n",
    "    if not aligned:        \n",
    "        input_sequence = align(input_sequence, label_sequence)\n",
    "\n",
    "    # subsample and smooth data \n",
    "    input_sequence_ = subsample(input_sequence, d_sample)\n",
    "    input_sequence_ = smooth(input_sequence_, sigma)\n",
    "    \n",
    "    label_sequence_ = subsample(label_sequence, d_sample)\n",
    "    label_sequence_ = smooth(label_sequence_, sigma)\n",
    "\n",
    "    # convert into X and y sequences\n",
    "    X, y = subsequences(input_sequence_, label_sequence_, n_steps)\n",
    "    y = np.reshape(y, (-1, 1))\n",
    "\n",
    "    # fit and scale X\n",
    "    scaler_X = MinMaxScaler(feature_range = (0, 1))\n",
    "    scaler_X.fit(X)\n",
    "    X_scaled = scaler_X.transform(X)\n",
    "\n",
    "    # fit and scale y\n",
    "    scaler_y = MinMaxScaler(feature_range = (0, 1))\n",
    "    scaler_y.fit(y)\n",
    "    y_scaled = scaler_y.transform(y)\n",
    "\n",
    "    # reshape into correct format\n",
    "    X_scaled = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1)\n",
    "    \n",
    "    return X_scaled, y_scaled, scaler_y\n",
    "\n",
    "def prepare_data_unscaled(input_sequence, label_sequence, aligned, d_sample, n_steps, sigma):\n",
    "    # align data if not of equal size\n",
    "    if not aligned:        \n",
    "        input_sequence = align(input_sequence, label_sequence)\n",
    "\n",
    "    # subsample and smooth data \n",
    "    input_sequence_ = subsample(input_sequence, d_sample)\n",
    "    input_sequence_ = smooth(input_sequence_, gauss_sigma)\n",
    "    \n",
    "    label_sequence_ = subsample(label_sequence, d_sample)\n",
    "    label_sequence_ = smooth(label_sequence_, gauss_sigma)\n",
    "\n",
    "    # convert into X and y sequences\n",
    "    X, y = subsequences(input_sequence_, label_sequence_, n_steps)\n",
    "    y = np.reshape(y, (-1, 1))\n",
    "\n",
    "    # reshape into correct format\n",
    "    X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------- Hyperparameters -------------------------------------------\n",
    "n_steps = 50\n",
    "n_features = 2\n",
    "n_lstm_units_1 = 50\n",
    "n_lstm_units_2 = 20\n",
    "n_dense_units = 10\n",
    "n_epochs = 10\n",
    "\n",
    "d_sample = 1\n",
    "gauss_sigma = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------- Prepare Training Data -------------------------------------------\n",
    "# single profile\n",
    "train_cur_inv = np.loadtxt('../data/fobss_data/data/osc_19_11_18/inverter/Inverter_Current.csv', delimiter=';')\n",
    "train_cur_inv = train_cur_inv[:,1]\n",
    "train_volt_slave_0_cell_4 = np.loadtxt('../data/fobss_data/data/osc_19_11_18/cells/Slave_0_Cell_Voltages.csv', delimiter=';')\n",
    "train_volt_slave_0_cell_4 = train_volt_slave_0_cell_4[:,4]\n",
    "train_volt_repeat = np.full(shape=train_volt_slave_0_cell_4.shape[0], fill_value=train_volt_slave_0_cell_4[0], dtype=np.float)\n",
    "\n",
    "X1_train, y_train_single, _ = prepare_data(train_cur_inv, train_volt_slave_0_cell_4, False, d_sample, n_steps, gauss_sigma)\n",
    "\n",
    "inv_cum = np.cumsum(train_cur_inv)\n",
    "X2_train, _, _ = prepare_data(inv_cum, train_volt_slave_0_cell_4, False, d_sample, n_steps, gauss_sigma)\n",
    "\n",
    "X_train_single = np.append(X1_train, X2_train, axis=2)\n",
    "\n",
    "print('Single Profile:', X_train_single.shape, y_train_single.shape)\n",
    "\n",
    "# multiple profiles \n",
    "cur_profile_1 = np.loadtxt('../data/fobss_data/data/Profile 10A/inverter/Inverter_Current.csv', delimiter=';')\n",
    "cur_profile_1 = cur_profile_1[:,1]\n",
    "volt_profil_1 = np.loadtxt('../data/fobss_data/data/Profile 10A/cells/Slave_0_Cell_Voltages.csv', delimiter=';')\n",
    "volt_profil_1 = volt_profil_1[:,4]\n",
    "\n",
    "cur_profile_2 = np.loadtxt('../data/fobss_data/data/Profile -10A/inverter/Inverter_Current.csv', delimiter=';')\n",
    "cur_profile_2 = cur_profile_2[:,1]\n",
    "volt_profil_2 = np.loadtxt('../data/fobss_data/data/Profile -10A/cells/Slave_0_Cell_Voltages.csv', delimiter=';')\n",
    "volt_profil_2 = volt_profil_2[:,4]\n",
    "\n",
    "cur_profile_3 = np.loadtxt('../data/fobss_data/data/Profile 25A/inverter/Inverter_Current.csv', delimiter=';')\n",
    "cur_profile_3 = cur_profile_3[:,1]\n",
    "volt_profil_3 = np.loadtxt('../data/fobss_data/data/Profile 25A/cells/Slave_0_Cell_Voltages.csv', delimiter=';')\n",
    "volt_profil_3 = volt_profil_3[:,4]\n",
    "\n",
    "cur_profile_4 = np.loadtxt('../data/fobss_data/data/Profile -25A/inverter/Inverter_Current.csv', delimiter=';')\n",
    "cur_profile_4 = cur_profile_4[:,1]\n",
    "volt_profil_4 = np.loadtxt('../data/fobss_data/data/Profile -25A/cells/Slave_0_Cell_Voltages.csv', delimiter=';')\n",
    "volt_profil_4 = volt_profil_4[:,4]\n",
    "\n",
    "# align and cut multiple profiles\n",
    "cur_profile_1 = align(cur_profile_1, cur_profile_1)\n",
    "cur_profile_1 = cur_profile_1[:2000]\n",
    "volt_profile_1 = volt_profil_1[:2000]\n",
    "\n",
    "cur_profile_2 = align(cur_profile_2, cur_profile_2)\n",
    "cur_profile_2 = cur_profile_2[:2000]\n",
    "volt_profile_2 = volt_profil_2[:2000]\n",
    "\n",
    "cur_profile_3 = align(cur_profile_3, cur_profile_3)\n",
    "cur_profile_3 = cur_profile_3[:2000]\n",
    "volt_profile_3 = volt_profil_3[:2000]\n",
    "\n",
    "cur_profile_4 = align(cur_profile_4, cur_profile_4)\n",
    "cur_profile_4 = cur_profile_4[:2000]\n",
    "volt_profile_4 = volt_profil_4[:2000]\n",
    "\n",
    "# shape into correct input format\n",
    "stacked_prof_volt = np.stack([volt_profile_1, volt_profile_2, volt_profile_3, volt_profile_4], axis=0).flatten()\n",
    "stacked_prof_cur = np.stack([cur_profile_1, cur_profile_2, cur_profile_3, cur_profile_4], axis=0).flatten()\n",
    "\n",
    "X1_train, y_train, _ = prepare_data(stacked_prof_cur, stacked_prof_volt, False, d_sample, n_steps, gauss_sigma)\n",
    "\n",
    "# prepare second input data\n",
    "stacked_prof_volt = np.stack([volt_profile_1, volt_profile_2, volt_profile_3, volt_profile_4], axis=0).flatten()\n",
    "stacked_prof_cur = np.stack([cur_profile_1, cur_profile_2, cur_profile_3, cur_profile_4], axis=0).flatten()\n",
    "cum_prof_cur = np.cumsum(stacked_prof_cur)\n",
    "X2_train, _, _ = prepare_data(cum_prof_cur, stacked_prof_volt, False, d_sample, n_steps, gauss_sigma)\n",
    "\n",
    "X_train = np.append(X1_train, X2_train, axis=2)\n",
    "print('Multiple Profiles:', X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------- Initialize LSTM -------------------------------------------\n",
    "model = keras.Sequential()\n",
    "\n",
    "# Adding the first LSTM layer and some Dropout regularisation\n",
    "model.add(layers.LSTM(units = n_lstm_units_1, input_shape = (n_steps, n_features), return_sequences=True))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "\n",
    "model.add(layers.LSTM(units = n_lstm_units_2))\n",
    "model.add(layers.LeakyReLU(alpha=0.1))\n",
    "# Adding the output layer\n",
    "model.add(layers.Dense(1, activation='tanh'))\n",
    "\n",
    "# Show model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------- Train LSTM -------------------------------------------\n",
    "model.compile(optimizer = 'adam', loss = 'mse', metrics=[\"mae\"])\n",
    "\n",
    "# Fitting the LSTM to the Training set\n",
    "history = model.fit(X_train_single, y_train_single, epochs = n_epochs, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------- Visualize Training -------------------------------------------\n",
    "loss = history.history['loss']\n",
    "metrics = history.history['mae']\n",
    "epochs = range(1,len(loss)+1)\n",
    "\n",
    "# plot graph\n",
    "plt.subplots(figsize = (5,5))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(epochs,loss,'-o',label='training loss')\n",
    "plt.legend()\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(epochs,metrics,'-o', color='green',label='absolute error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------- Prepare Test Data -------------------------------------------\n",
    "# load data\n",
    "test_cur_inv = np.loadtxt('../data/fobss_data/data/osc_19_11_18/inverter/Inverter_Current.csv', delimiter=';')\n",
    "test_cur_inv = test_cur_inv[:,1]\n",
    "test_volt_slave_0_cell_4 = np.loadtxt('../data/fobss_data/data/osc_19_11_18/cells/Slave_0_Cell_Voltages.csv', delimiter=';')\n",
    "test_volt_slave_0_cell_4 = test_volt_slave_0_cell_4[:,4]\n",
    "\n",
    "# prepare prediction\n",
    "X1_test1, y_test1, scaler_y1 = prepare_data(test_cur_inv, test_volt_slave_0_cell_4, False, d_sample, n_steps, gauss_sigma)\n",
    "inv_cum1 = np.cumsum(test_cur_inv)\n",
    "X2_test1, _, _ = prepare_data(inv_cum1, test_volt_slave_0_cell_4, False, d_sample, n_steps, gauss_sigma)\n",
    "\n",
    "X_test1 = np.append(X1_test1, X2_test1, axis=2)\n",
    "\n",
    "print(X_test1.shape, y_test1.shape)\n",
    "\n",
    "# load data\n",
    "test_cur_inv = np.loadtxt('../data/fobss_data/data/stairs_19_11_18/inverter/Inverter_Current.csv', delimiter=';')\n",
    "test_cur_inv = test_cur_inv[:,1]\n",
    "test_volt_slave_0_cell_4 = np.loadtxt('../data/fobss_data/data/stairs_19_11_18/cells/Slave_0_Cell_Voltages.csv', delimiter=';')\n",
    "test_volt_slave_0_cell_4 = test_volt_slave_0_cell_4[:,4]\n",
    "\n",
    "# prepare prediction\n",
    "X1_test2, y_test2, scaler_y2 = prepare_data(test_cur_inv, test_volt_slave_0_cell_4, False, d_sample, n_steps, gauss_sigma)\n",
    "inv_cum2 = np.cumsum(test_cur_inv)\n",
    "X2_test2, _, _ = prepare_data(inv_cum2, test_volt_slave_0_cell_4, False, d_sample, n_steps, gauss_sigma)\n",
    "\n",
    "X_test2 = np.append(X1_test2, X2_test2, axis=2)\n",
    "\n",
    "print(X_test2.shape, y_test2.shape)\n",
    "\n",
    "# load data\n",
    "test_cur_inv = np.loadtxt('../data/fobss_data/data/Profile 10A 3x/inverter/Inverter_Current.csv', delimiter=';')\n",
    "test_cur_inv = test_cur_inv[:,1]\n",
    "test_volt_slave_0_cell_4 = np.loadtxt('../data/fobss_data/data/Profile 10A 3x/cells/Slave_0_Cell_Voltages.csv', delimiter=';')\n",
    "test_volt_slave_0_cell_4 = test_volt_slave_0_cell_4[:,4]\n",
    "\n",
    "# prepare prediction\n",
    "X1_test3, y_test3, scaler_y3 = prepare_data(test_cur_inv, test_volt_slave_0_cell_4, False, d_sample, n_steps, gauss_sigma)\n",
    "inv_cum3 = np.cumsum(test_cur_inv)\n",
    "X2_test3, _, _ = prepare_data(inv_cum3, test_volt_slave_0_cell_4, False, d_sample, n_steps, gauss_sigma)\n",
    "\n",
    "X_test3 = np.append(X1_test3, X2_test3, axis=2)\n",
    "\n",
    "print(X_test3.shape, y_test3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------- Predict on Test Data -------------------------------------------\n",
    "yhat1 = model.predict(X_test1, verbose = 1)\n",
    "yhat_rescaled1 = scaler_y1.inverse_transform(yhat1)\n",
    "y_test_unscaled1 = scaler_y1.inverse_transform(y_test1)\n",
    "\n",
    "yhat2 = model.predict(X_test2, verbose = 1)\n",
    "yhat_rescaled2 = scaler_y2.inverse_transform(yhat2)\n",
    "y_test_unscaled2 = scaler_y2.inverse_transform(y_test2)\n",
    "\n",
    "yhat3 = model.predict(X_test3, verbose = 1)\n",
    "yhat_rescaled3 = scaler_y3.inverse_transform(yhat3)\n",
    "y_test_unscaled3 = scaler_y3.inverse_transform(y_test3)\n",
    "\n",
    "\n",
    "# plot test results\n",
    "plt.subplots(figsize = (7,10))\n",
    "plt.subplot(3,1,1)\n",
    "plt.plot(yhat_rescaled1, color='red', label = 'predicted')\n",
    "plt.plot(y_test_unscaled1, color='blue', label = 'measured')\n",
    "plt.legend()\n",
    "plt.subplot(3,1,2)\n",
    "plt.plot(yhat_rescaled2, color='red', label = 'predicted')\n",
    "plt.plot(y_test_unscaled2, color='blue', label = 'measured')\n",
    "plt.legend()\n",
    "plt.subplot(3,1,3)\n",
    "plt.plot(yhat_rescaled3, color='red', label = 'predicted')\n",
    "plt.plot(y_test_unscaled3, color='blue', label = 'measured')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "battery-system",
   "language": "python",
   "name": "battery-system"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
